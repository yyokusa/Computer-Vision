{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import moviepy.video.io.VideoFileClip as mpy\n",
    "import moviepy.editor as mpyeditor\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_count:  94\n",
      "video_fps:  25.0\n"
     ]
    }
   ],
   "source": [
    "vid = mpy.VideoFileClip('part1_video.mp4')\n",
    "\n",
    "frame_count = vid.reader.nframes # 92 frames\n",
    "video_fps = vid.fps\n",
    "\n",
    "print('frame_count: ', frame_count)\n",
    "print('video_fps: ', video_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height width channels = image.shape\n",
    "\n",
    "for i in range(10, frame_count):\n",
    "    # type(frame): <class 'numpy.ndarray'>\n",
    "    frame = vid.get_frame(i * 1.0 / video_fps)\n",
    "    frame = frame.copy()\n",
    "\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # edges = cv2.Canny(img,100,200, 3, True)\n",
    "    edges = cv2.Canny(img,100,200)\n",
    "    # plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "    cv2.imwrite('original.png', img)\n",
    "    # plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "    # plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "    cv2.imwrite('edges.png', edges)\n",
    "    # plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "    # plt.show()\n",
    "    break\n",
    "\n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "    #result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst,None)\n",
    "    # Threshold for an optimal value, it may vary depending on the image.\n",
    "    frame[dst>0.01*dst.max()] = [0,0,255]\n",
    "    if i != 0 and i % 15 == 0:\n",
    "        # plt.imshow(frame)\n",
    "        cv2.imwrite('test.png', frame)\n",
    "        print('count: ', len(frame[dst > 0.01 * dst.max()]))\n",
    "        # print('count: ', frame[dst > 0.01 * dst.max()])\n",
    "        break\n",
    "    # if cv2.waitKey(0) & 0xff == 27:\n",
    "    #     cv2.destroyAllWindows()\n",
    "\n",
    "    # 5gen -> 133\n",
    "    # 4gen 274 - 133 = 141\n",
    "    # yildiz 520 - 274 = 246\n",
    "    # yildiz 744 - 520 = 224\n",
    "    # 5gen 867 - 744 = 123\n",
    "    # 5gen 971 - 867 = 104\n",
    "    # 5gen 1094 - 971 = 123\n",
    "    # 5gen 1218 - 1094 = 124\n",
    "    # 4gen 1350 - 1218 = 132\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HoughLine\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#First, get the gray image and process GaussianBlur.\n",
    "# img = cv2.imread('D:\\\\Users\\\\Administrator\\\\PycharmProjects\\\\EdgeDetect\\\\venv\\\\sample\\\\{}'.format(samplename))\n",
    "img = cv2.imread(\"edges.png\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernel_size = 5\n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "\n",
    "#Second, process edge detection use Canny.\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "# cv2.imshow('photo2',edges)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imwrite('canny_applied.png',edges)\n",
    "#Then, use HoughLinesP to get the lines. You can adjust the parameters for better performance.\n",
    "\n",
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 1  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 10  # minimum number of pixels making up a line\n",
    "max_line_gap = 5  # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "print(lines)\n",
    "print(len(lines))\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2 ),(255,0,0),5)\n",
    "\n",
    "#Finally, draw the lines on your srcImage.\n",
    "# Draw the lines on the  image\n",
    "lines_edges = cv2.addWeighted(img, 0.8, line_image, 1, 0)\n",
    "# cv2.imshow('photo',lines_edges)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imwrite('lines_drawed.png',lines_edges)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.imwrite('.\\\\detected\\\\{}'.format(\"p14_\"+samplename),lines_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input INPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"7a44498a-c233-4718-b927-820a57cf6715\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/var/folders/r6/0xk0j5q14y51k5wqpq9gqqgm0000gn/T/tmp-79334flDeqogZCxIo.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random as rng\n",
    "myHarris_window = 'My Harris corner detector'\n",
    "myShiTomasi_window = 'My Shi Tomasi corner detector'\n",
    "myHarris_qualityLevel = 50\n",
    "myShiTomasi_qualityLevel = 50\n",
    "max_qualityLevel = 100\n",
    "rng.seed(12345)\n",
    "def myHarris_function(val):\n",
    "    myHarris_copy = np.copy(src)\n",
    "    myHarris_qualityLevel = max(val, 1)\n",
    "    for i in range(src_gray.shape[0]):\n",
    "        for j in range(src_gray.shape[1]):\n",
    "            if Mc[i,j] > myHarris_minVal + ( myHarris_maxVal - myHarris_minVal )*myHarris_qualityLevel/max_qualityLevel:\n",
    "                cv.circle(myHarris_copy, (j,i), 4, (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256)), cv.FILLED)\n",
    "    cv.imshow(myHarris_window, myHarris_copy)\n",
    "def myShiTomasi_function(val):\n",
    "    myShiTomasi_copy = np.copy(src)\n",
    "    myShiTomasi_qualityLevel = max(val, 1)\n",
    "    for i in range(src_gray.shape[0]):\n",
    "        for j in range(src_gray.shape[1]):\n",
    "            if myShiTomasi_dst[i,j] > myShiTomasi_minVal + ( myShiTomasi_maxVal - myShiTomasi_minVal )*myShiTomasi_qualityLevel/max_qualityLevel:\n",
    "                cv.circle(myShiTomasi_copy, (j,i), 4, (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256)), cv.FILLED)\n",
    "    cv.imshow(myShiTomasi_window, myShiTomasi_copy)\n",
    "# Load source image and convert it to gray\n",
    "parser = argparse.ArgumentParser(description='Code for Creating your own corner detector tutorial.')\n",
    "parser.add_argument('--input', help='Path to input image.', default='original.png')\n",
    "args = parser.parse_args()\n",
    "src = cv.imread(cv.samples.findFile(args.input))\n",
    "if src is None:\n",
    "    print('Could not open or find the image:', args.input)\n",
    "    exit(0)\n",
    "src_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "# Set some parameters\n",
    "blockSize = 3\n",
    "apertureSize = 3\n",
    "# My Harris matrix -- Using cornerEigenValsAndVecs\n",
    "myHarris_dst = cv.cornerEigenValsAndVecs(src_gray, blockSize, apertureSize)\n",
    "# calculate Mc\n",
    "Mc = np.empty(src_gray.shape, dtype=np.float32)\n",
    "for i in range(src_gray.shape[0]):\n",
    "    for j in range(src_gray.shape[1]):\n",
    "        lambda_1 = myHarris_dst[i,j,0]\n",
    "        lambda_2 = myHarris_dst[i,j,1]\n",
    "        Mc[i,j] = lambda_1*lambda_2 - 0.04*pow( ( lambda_1 + lambda_2 ), 2 )\n",
    "myHarris_minVal, myHarris_maxVal, _, _ = cv.minMaxLoc(Mc)\n",
    "# Create Window and Trackbar\n",
    "cv.namedWindow(myHarris_window)\n",
    "cv.createTrackbar('Quality Level:', myHarris_window, myHarris_qualityLevel, max_qualityLevel, myHarris_function)\n",
    "myHarris_function(myHarris_qualityLevel)\n",
    "# My Shi-Tomasi -- Using cornerMinEigenVal\n",
    "myShiTomasi_dst = cv.cornerMinEigenVal(src_gray, blockSize, apertureSize)\n",
    "myShiTomasi_minVal, myShiTomasi_maxVal, _, _ = cv.minMaxLoc(myShiTomasi_dst)\n",
    "# Create Window and Trackbar\n",
    "cv.namedWindow(myShiTomasi_window)\n",
    "cv.createTrackbar('Quality Level:', myShiTomasi_window, myShiTomasi_qualityLevel, max_qualityLevel, myShiTomasi_function)\n",
    "myShiTomasi_function(myShiTomasi_qualityLevel)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
